{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7107fd08-87f1-4432-9a72-88be338997c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " audio_input (InputLayer)       [(None, 5000, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 28, 28, 32)   320         ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 5000, 32)     128         ['audio_input[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 32)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 2500, 32)    0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 14, 14, 64)   18496       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 2500, 64)     6208        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 64)    0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 1250, 64)    0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 3136)         0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 80000)        0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " image_hidden (Dense)           (None, 300)          941100      ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " audio_hidden (Dense)           (None, 300)          24000300    ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      " combined_hidden (Add)          (None, 300)          0           ['image_hidden[0][0]',           \n",
      "                                                                  'audio_hidden[0][0]']           \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 10)           3010        ['combined_hidden[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,969,562\n",
      "Trainable params: 24,969,562\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 2s 103ms/step - loss: 3.4219 - accuracy: 0.1109 - val_loss: 2.3576 - val_accuracy: 0.0875\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 2.3123 - accuracy: 0.1281 - val_loss: 2.2815 - val_accuracy: 0.1375\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 2.2093 - accuracy: 0.2141 - val_loss: 2.3368 - val_accuracy: 0.1375\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 2.0556 - accuracy: 0.2766 - val_loss: 2.2331 - val_accuracy: 0.1937\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 1.7905 - accuracy: 0.4109 - val_loss: 2.0869 - val_accuracy: 0.2438\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 1.3583 - accuracy: 0.6031 - val_loss: 2.1054 - val_accuracy: 0.2375\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.9560 - accuracy: 0.7547 - val_loss: 2.1127 - val_accuracy: 0.2750\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 0.5584 - accuracy: 0.8906 - val_loss: 2.1774 - val_accuracy: 0.2875\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 0.3352 - accuracy: 0.9484 - val_loss: 2.1626 - val_accuracy: 0.3313\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.1689 - accuracy: 0.9859 - val_loss: 2.2251 - val_accuracy: 0.3063\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7840 - accuracy: 0.4600\n",
      "Точность на тестовой выборке: 46.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Conv1D, MaxPooling1D, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import glob\n",
    "import librosa\n",
    "\n",
    "# Функция загрузки полного набора MNIST\n",
    "def load_full_mnist():\n",
    "    \"\"\"\n",
    "    Загрузка полной выборки MNIST (784 входных признака + класс метки [0..9]).\n",
    "    Нормировка входных пикселей к диапазону [0, 1].\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('mnist_784.csv')\n",
    "    X = df.iloc[:, 0:784].values / 255.0\n",
    "    y = df.iloc[:, 784].values  \n",
    "    return X, y\n",
    "\n",
    "# Функция для удаления тишины с начала и конца аудиосигнала\n",
    "def extract_useful_signal(signal, sr, top_db=20):\n",
    "    trimmed_signal, idx = librosa.effects.trim(signal, top_db=top_db)\n",
    "    return trimmed_signal\n",
    "\n",
    "# Функция загрузки и предварительной обработки аудио\n",
    "def load_preprocess_audio(num_samples, target_length=5000):\n",
    "    audio_files = glob.glob('free-spoken-digit-dataset/recordings/*.wav')\n",
    "    np.random.shuffle(audio_files)\n",
    "    selected_files = audio_files[:num_samples]\n",
    "    \n",
    "    X_audio_list = []\n",
    "    digits_audio = []\n",
    "\n",
    "    for file in selected_files:\n",
    "        base_name = file.split('/')[-1]\n",
    "        digit_str = base_name.split('_')[0]\n",
    "        audio_digit = int(digit_str)\n",
    "        digits_audio.append(audio_digit)\n",
    "         \n",
    "        signal, sr = librosa.load(file, sr=None)\n",
    "        extract = extract_useful_signal(signal, sr, top_db=20)            \n",
    "\n",
    "        if len(extract) > target_length:\n",
    "            signal = extract[:target_length]\n",
    "        else:\n",
    "            signal = np.pad(extract, (0, target_length - len(extract)), 'constant')\n",
    "        \n",
    "        # Масштабирование сигнала к диапазону [0, 1]\n",
    "        min_val, max_val = np.min(signal), np.max(signal)\n",
    "        if max_val - min_val < 1e-12:\n",
    "            signal = np.zeros_like(signal)\n",
    "        else:\n",
    "            signal = (signal - min_val) / (max_val - min_val)\n",
    "        \n",
    "        X_audio_list.append(signal)\n",
    "    \n",
    "    X_audio = np.array(X_audio_list)\n",
    "    return X_audio, sr, digits_audio\n",
    "\n",
    "# Функция сопоставления изображений MNIST с аудиоданными на основе метки цифры\n",
    "def match_images_to_audio_digits(X, y, digits_audio, num_samples):\n",
    "    matched_images = []\n",
    "    for d in digits_audio:\n",
    "        indices = np.where(y == d)[0]\n",
    "        if len(indices) == 0:\n",
    "            raise ValueError(f\"Не найдено изображений в MNIST с цифрой {d}\")\n",
    "        idx = np.random.choice(indices)\n",
    "        matched_images.append(X[idx])\n",
    "    matched_images = np.array(matched_images)\n",
    "    return matched_images\n",
    "\n",
    "# ------------------------------\n",
    "# Подготовка данных для CNN\n",
    "# ------------------------------\n",
    "num_samples = 1000\n",
    "\n",
    "# Загрузка и обработка MNIST\n",
    "X_full, y_full = load_full_mnist()\n",
    "# Получение изображений, соответствующих аудиозаписям\n",
    "X_image = match_images_to_audio_digits(X_full, y_full, \n",
    "                                       digits_audio=load_preprocess_audio(num_samples)[2], \n",
    "                                       num_samples=num_samples)\n",
    "# Приведение изображений к форме (28, 28, 1)\n",
    "X_image = X_image.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Загрузка и обработка аудио\n",
    "X_audio, sr, digits_audio = load_preprocess_audio(num_samples=num_samples, target_length=5000)\n",
    "# Приведение аудио к форме (5000, 1)\n",
    "X_audio = X_audio.reshape(-1, 5000, 1)\n",
    "\n",
    "# Используем метки из аудиоданных (цифры)\n",
    "y_labels = np.array(digits_audio)\n",
    "\n",
    "# Разбиение на обучающую и тестовую выборки\n",
    "X_image_train, X_image_test, X_audio_train, X_audio_test, y_train, y_test = train_test_split(\n",
    "    X_image, X_audio, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
    "\n",
    "# ------------------------------\n",
    "# Определение архитектуры CNN\n",
    "# ------------------------------\n",
    "# Ветвь для обработки изображений (MNIST)\n",
    "image_input = Input(shape=(28, 28, 1), name='image_input')\n",
    "x = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(image_input)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "# Скрытое представление размерности 300\n",
    "image_hidden = Dense(300, activation='relu', name='image_hidden')(x)\n",
    "\n",
    "# Ветвь для обработки аудио\n",
    "audio_input = Input(shape=(5000, 1), name='audio_input')\n",
    "y = Conv1D(filters=32, kernel_size=3, activation='relu', padding='same')(audio_input)\n",
    "y = MaxPooling1D(pool_size=2)(y)\n",
    "y = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(y)\n",
    "y = MaxPooling1D(pool_size=2)(y)\n",
    "y = Flatten()(y)\n",
    "# Скрытое представление размерности 300\n",
    "audio_hidden = Dense(300, activation='relu', name='audio_hidden')(y)\n",
    "\n",
    "# Объединение представлений (операция суммирования)\n",
    "combined_hidden = Add(name='combined_hidden')([image_hidden, audio_hidden])\n",
    "\n",
    "# Финальный классификатор\n",
    "output = Dense(10, activation='softmax', name='output')(combined_hidden)\n",
    "\n",
    "model_cnn = Model(inputs=[image_input, audio_input], outputs=output)\n",
    "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_cnn.summary()\n",
    "\n",
    "# ------------------------------\n",
    "# Обучение модели\n",
    "# ------------------------------\n",
    "history = model_cnn.fit([X_image_train, X_audio_train], y_train, \n",
    "                         epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ------------------------------\n",
    "# Оценка классификации\n",
    "# ------------------------------\n",
    "test_loss, test_accuracy = model_cnn.evaluate([X_image_test, X_audio_test], y_test)\n",
    "print(\"Точность на тестовой выборке: {:.2f}%\".format(test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd4301f-2a6d-4565-8f0c-f91b6a48554e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
